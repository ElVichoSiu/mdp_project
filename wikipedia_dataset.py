# -*- coding: utf-8 -*-
"""PATOS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RmRMrtZW2nTNopPq5rdBrBB88G9-tio4

Código para crear dataset apartir de datos de Wikipedia Laura Maldonado Lagos, Vicente Thiele Muñoz y Javiera Romero Orrego Grupo 2

Primero desde cada página de wikipedia extraemos la informacion
"""

import pandas as pd
url = 'https://en.wikipedia.org/wiki/List_of_fiction_works_made_into_feature_films_(0%E2%80%939,_A%E2%80%93C)'
pagina = pd.read_html(url)
lineas_relevantes = pagina[2:] #ignoramos las primeras lineas que son irrelevantes
df = pd.concat(lineas_relevantes, ignore_index=True)
df.columns = ['fiction_work', 'film_adaptation'] #le ponemos nombres a las columnas
df.to_csv('fiction_to_filmsA-C.csv', index=False) #guardamos la info al csv

"""Repetimos lo mismo para cada página"""

url = 'https://en.wikipedia.org/wiki/List_of_fiction_works_made_into_feature_films_(D%E2%80%93J)'
pagina = pd.read_html(url)
lineas_relevantes = pagina[2:]
df = pd.concat(lineas_relevantes, ignore_index=True)
df.columns = ['fiction_work', 'film_adaptation']
df.to_csv('fiction_to_filmsD-J.csv', index=False)

url = 'https://en.wikipedia.org/wiki/List_of_fiction_works_made_into_feature_films_(K%E2%80%93R)'
pagina = pd.read_html(url)
lineas_relevantes = pagina[3:]
df = pd.concat(lineas_relevantes, ignore_index=True)
df.columns = ['fiction_work', 'film_adaptation']
df.to_csv('fiction_to_filmsK-R.csv', index=False)

url = 'https://en.wikipedia.org/wiki/List_of_fiction_works_made_into_feature_films_(S%E2%80%93Z)'
pagina = pd.read_html(url)
lineas_relevantes = pagina[2:]
df = pd.concat(lineas_relevantes, ignore_index=True)
df.columns = ['fiction_work', 'film_adaptation']
df.to_csv('fiction_to_filmsS-Z.csv', index=False)

"""Ahora combinamos todos los csv en uno solo"""

import pandas as pd
import re
csv_files = [
    'fiction_to_filmsA-C.csv',
    'fiction_to_filmsD-J.csv',
    'fiction_to_filmsK-R.csv',
    'fiction_to_filmsS-Z.csv'
]

combined_df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)
#habian algunos valores con formatos extraños al final tipo [N 10] por eso este map
combined_df = combined_df.applymap(
    lambda x: re.sub(r'\[N \d{1,2}\]', '', x).replace('"', '').strip() if isinstance(x, str) else x
)
#para extraer solo el titulo sin el (año)
def clean_title(title):
    return re.sub(r'\s*\(\d{4}\)\s*$', '', title).strip()
#
def extract_info(row):
    text = row['fiction_work']
    film = row.get('film_adaptation', '')
    series_match = re.match(r'^(.*?)\s*\((\d{4}–\d{4})\)\s*\(series\),\s*(.+)$', text)
    if series_match:
        _, date_range, author = series_match.groups()
        title = clean_title(film)
        return pd.Series([title, date_range, author])
    match = re.match(r"^(.*?)(?:\s*\(.*?\))?\s*\((\d{4})\),\s*(.*)$", text)
    if match:
        title, year, author = match.groups()
        return pd.Series([title.strip(), year, author.strip()])
    return pd.Series([text, None, None])


combined_df[['fiction_work', 'releaseDate', 'author']] = combined_df.apply(extract_info, axis=1)


combined_df.sort_values(by='fiction_work', inplace=True)
combined_df.to_csv('combined_fiction_to_films.csv', index=False)

"""Para conocer el tamañano del dataset creado"""

print(f"Cantidad de filas: {len(combined_df)}")

"""Para conocer la cantidad de libros únicos que tiene, ya que un libro puede estar asociado a 1 o más películas"""

import pandas as pd
df = pd.read_csv('combined_fiction_to_films.csv')
unique_fiction_df = df.drop_duplicates(subset='fiction_work')
unique_fiction_df.to_csv('unique_fiction_works.csv', index=False)
print(f"Cantidad de libros únicos: {len(unique_fiction_df)}")

pip install requests pandas

"""En esta parte ocupamos una API para conseguir la fecha de estreno completa en estados unidos para cada pelicula, ademas se deja en formato mas limpio donde fiction_work va a ser solo el título y tendermos la fecha en la columna us_release_date"""

import pandas as pd
import requests
import re
import time

TMDB_API_KEY = '44bd9da62a42d8adfb46a54603d07f66'

df = pd.read_csv('combined_fiction_to_films.csv')

def extract_title_year(film):
    match = re.match(r'^(.*?)\s*\((\d{4})\)$', str(film))
    if match:
        return match.group(1).strip(), int(match.group(2))
    return film, None

df['parsed_title'], df['parsed_year'] = zip(*df['film_adaptation'].map(extract_title_year))

unique_films = df[['parsed_title', 'parsed_year']].dropna().drop_duplicates()
release_dates = {}

for _, row in unique_films.iterrows():
    title, year = row['parsed_title'], row['parsed_year']
    try:
        search_url = 'https://api.themoviedb.org/3/search/movie'
        params = {
            'api_key': TMDB_API_KEY,
            'query': title,
            'year': year,
            'include_adult': False
        }
        res = requests.get(search_url, params=params)
        res.raise_for_status()
        results = res.json().get('results', [])

        if not results:
            print(f"[Not Found] {title} ({year})")
            release_dates[(title, year)] = None
            continue

        movie_id = results[0]['id']

        release_url = f'https://api.themoviedb.org/3/movie/{movie_id}/release_dates'
        res = requests.get(release_url, params={'api_key': TMDB_API_KEY})
        res.raise_for_status()
        all_releases = res.json().get('results', [])

        us_release = next((rel for rel in all_releases if rel['iso_3166_1'] == 'US'), None)
        if us_release:
            release_info = next(
                (r for r in us_release['release_dates'] if r['type'] == 3),  # Theatrical
                us_release['release_dates'][0]
            )
            release_date = release_info['release_date'][:10]
            release_dates[(title, year)] = release_date
            print(f"[OK] {title} ({year}): {release_date}")
        else:
            print(f"[No hay fecha de estreno] {title} ({year})")
            release_dates[(title, year)] = None

        time.sleep(0.3)
    except Exception as e:
        print(f"[Error] {title} ({year}): {e}")
        release_dates[(title, year)] = None
def get_final_release_date(row):
    key = (row['parsed_title'], row['parsed_year'])
    date = release_dates.get(key)
    if date:
        return date
    elif pd.notnull(row['parsed_year']):
        return f"{int(row['parsed_year'])}-01-01"
    else:
        return None

df['us_release_date'] = df.apply(get_final_release_date, axis=1)
df['film_adaptation'] = df['parsed_title']

df = df.drop(columns=['parsed_title', 'parsed_year'])

df.to_csv('final_fiction_to_film.csv', index=False)
